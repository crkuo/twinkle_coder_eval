#!/usr/bin/env python3
"""
åŸºæœ¬ç³»çµ±æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ä¸éœ€è¦ transformers çš„æ ¸å¿ƒåŠŸèƒ½
"""
import yaml
import numpy as np
from tqdm import tqdm
import os
import sys


def test_config_parsing():
    """æ¸¬è©¦é…ç½®è§£æ"""
    print("ğŸ§ª æ¸¬è©¦é…ç½®è§£æ...")
    
    with open('configs/test_mbpp_config.yml', 'r') as f:
        config = yaml.safe_load(f)
    
    assert config['name'] == "Test MBPP Evaluation"
    assert config['model']['backend'][0]['type'] == 'vllm'
    assert config['evaluation']['benchmark'][0]['type'] == 'MBPP'
    
    print("âœ… é…ç½®è§£ææ­£å¸¸")
    return config


def test_args_creation(config):
    """æ¸¬è©¦åƒæ•¸å‰µå»º"""
    print("ğŸ§ª æ¸¬è©¦åƒæ•¸å‰µå»º...")
    
    class Args:
        def __init__(self):
            # æ¨¡å‹é…ç½®
            model_config = config.get('model', {})
            backend_config = model_config.get('backend', [{}])[0]
            
            self.model_name = backend_config.get('model_name', 'default_model')
            self.tokenizer_name = backend_config.get('tokenizer_name')
            self.model_type = backend_config.get('model_type', 'Instruction')
            self.num_gpus = backend_config.get('num_gpus', 1)
            self.batch_size = backend_config.get('batch_size', 1)
            self.temperature = backend_config.get('temperature', 0.0)
            self.trust_remote_code = backend_config.get('trust_remote_code', True)
            self.max_tokens = backend_config.get('max_tokens', 1024)
            
            # è©•ä¼°é…ç½®
            eval_config = config.get('evaluation', {})
            benchmark_config = eval_config.get('benchmark', [{}])[0]
            
            self.task = benchmark_config.get('type', 'MBPP')
            self.prompt_type = benchmark_config.get('prompt_type', 'Instruction')
            self.num_samples = eval_config.get('num_samples', 200)
            self.num_workers = eval_config.get('num_workers', 1)
            
            # æç¤ºé…ç½®
            self.prompt_prefix = eval_config.get('prompt_prefix', '')
            self.prompt_suffix = eval_config.get('prompt_suffix', '')
            self.response_prefix = eval_config.get('response_prefix', '')
            self.response_suffix = eval_config.get('response_suffix', '')
            
            # è¼¸å‡ºé…ç½®
            output_config = eval_config.get('output', {})
            self.save_path = output_config.get('path', './output')
    
    args = Args()
    
    assert args.model_name == "deepseek-ai/deepseek-coder-6.7b-instruct"
    assert args.task == "MBPP"
    assert args.prompt_type == "Instruction"
    
    print("âœ… åƒæ•¸å‰µå»ºæ­£å¸¸")
    return args


def test_basic_utils():
    """æ¸¬è©¦åŸºæœ¬å·¥å…·å‡½æ•¸ï¼ˆä¸éœ€è¦ transformersï¼‰"""
    print("ğŸ§ª æ¸¬è©¦åŸºæœ¬å·¥å…·å‡½æ•¸...")
    
    # æ¸¬è©¦æ–‡æœ¬è™•ç†
    def refine_text(text: str) -> str:
        text = text.replace("\t", "    ")
        text = text.replace("\r\n", "\n").replace("\r", "\n")
        return text.strip() + "\n"
    
    test_text = "hello\tworld\r\n"
    refined = refine_text(test_text)
    expected = "hello    world\n"
    assert refined == expected
    
    # æ¸¬è©¦ group_and_count
    def group_and_count(lst, group_key, count_key):
        from collections import defaultdict
        grouped_counts = defaultdict(int)
        
        for item in lst:
            group = item.get(group_key)
            if group not in grouped_counts:
                grouped_counts[group] = 0
            if item.get(count_key) == True:
                grouped_counts[group] += 1
        
        return list(grouped_counts.values())
    
    test_data = [
        {'task_id': 'task1', 'passed': True},
        {'task_id': 'task1', 'passed': False},
        {'task_id': 'task2', 'passed': True},
    ]
    
    result = group_and_count(test_data, 'task_id', 'passed')
    assert result == [1, 1]  # task1: 1 passed, task2: 1 passed
    
    print("âœ… åŸºæœ¬å·¥å…·å‡½æ•¸æ­£å¸¸")


def test_benchmark_loading():
    """æ¸¬è©¦åŸºæº–æ¸¬è©¦è¼‰å…¥"""
    print("ğŸ§ª æ¸¬è©¦åŸºæº–æ¸¬è©¦è¼‰å…¥...")
    
    try:
        from benchmark.MBPP.MBPP import MBPP
        
        # å‰µå»º MBPP å¯¦ä¾‹ï¼ˆä¸éœ€è¦å¯¦éš›è¼‰å…¥æ•¸æ“šï¼‰
        mbpp = MBPP(name="MBPP", prompt_type="Instruction")
        
        # æª¢æŸ¥åŸºæœ¬å±¬æ€§
        assert hasattr(mbpp, 'name')
        assert hasattr(mbpp, 'prompt_type')
        assert hasattr(mbpp, 'get_prompt')
        assert hasattr(mbpp, 'postprocess_generation')
        assert hasattr(mbpp, 'process_results')
        
        print("âœ… MBPP åŸºæº–æ¸¬è©¦è¼‰å…¥æ­£å¸¸")
        
    except Exception as e:
        print(f"âš ï¸  MBPP è¼‰å…¥å‡ºç¾å•é¡Œ: {e}")
        return False
    
    return True


def test_factory():
    """æ¸¬è©¦å·¥å» é¡"""
    print("ğŸ§ª æ¸¬è©¦å·¥å» é¡...")
    
    try:
        from factory import BenchmarkFactory
        
        # å‰µå»ºæ¨¡æ“¬ args
        class MockArgs:
            def __init__(self):
                self.task = "MBPP"
                self.prompt_type = "Instruction"
        
        args = MockArgs()
        
        # æ¸¬è©¦å·¥å» æ–¹æ³•
        task = BenchmarkFactory.get_task(args)
        assert task is not None
        assert hasattr(task, 'name')
        
        print("âœ… å·¥å» é¡æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âš ï¸  å·¥å» é¡æ¸¬è©¦å‡ºç¾å•é¡Œ: {e}")
        return False


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹åŸºæœ¬ç³»çµ±æ¸¬è©¦\n")
    
    os.chdir('/home/edward/twinkle_code_eval/refactor')
    
    try:
        # æ¸¬è©¦é…ç½®è§£æ
        config = test_config_parsing()
        
        # æ¸¬è©¦åƒæ•¸å‰µå»º
        args = test_args_creation(config)
        
        # æ¸¬è©¦åŸºæœ¬å·¥å…·å‡½æ•¸
        test_basic_utils()
        
        # æ¸¬è©¦åŸºæº–æ¸¬è©¦è¼‰å…¥
        benchmark_ok = test_benchmark_loading()
        
        # æ¸¬è©¦å·¥å» é¡
        factory_ok = test_factory()
        
        print("\nğŸ‰ åŸºæœ¬ç³»çµ±æ¸¬è©¦å®Œæˆï¼")
        print(f"é…ç½®ç³»çµ±: âœ…")
        print(f"å·¥å…·å‡½æ•¸: âœ…")
        print(f"åŸºæº–æ¸¬è©¦: {'âœ…' if benchmark_ok else 'âš ï¸'}")
        print(f"å·¥å» é¡: {'âœ…' if factory_ok else 'âš ï¸'}")
        
        if benchmark_ok and factory_ok:
            print("\nâœ¨ æ‰€æœ‰åŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼Œç³»çµ±å·²æ•´åˆå®Œæˆï¼")
            return True
        else:
            print("\nâš ï¸  éƒ¨åˆ†åŠŸèƒ½éœ€è¦èª¿æ•´")
            return False
            
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)